import streamlit as st
import pandas as pd
from bertopic import BERTopic
import os
from sentence_transformers import SentenceTransformer
import re

# Import underthesea cho ti·ªÅn x·ª≠ l√Ω ti·∫øng Vi·ªát
try:
    from underthesea import word_tokenize, sent_tokenize
except ImportError:
    st.error("Vui l√≤ng c√†i ƒë·∫∑t underthesea: pip install underthesea")
    st.stop()

# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N ---
TOPIC_INFO_PATH = r'C:\Users\PC\Desktop\BERTopic Model\reports\figures\topic_captions_final.csv'
MODEL_PATH = r'C:\Users\PC\Desktop\BERTopic Model\models\bertopic_model_colab'
EMBEDDING_MODEL_NAME = 'keepitreal/vietnamese-sbert'

# --- WRAPPER CLASS CHO EMBEDDING MODEL ---
class EmbeddingModelWrapper:
    """Wrapper ƒë·ªÉ BERTopic c√≥ th·ªÉ s·ª≠ d·ª•ng SentenceTransformer"""
    def __init__(self, model_name):
        self.model = SentenceTransformer(model_name)
    
    def embed_documents(self, texts, verbose=False, **kwargs):
        """Ph∆∞∆°ng th·ª©c m√† BERTopic c·∫ßn - ch·∫•p nh·∫≠n m·ªçi tham s·ªë"""
        return self.model.encode(texts, show_progress_bar=verbose)
    
    def embed(self, texts, verbose=False, **kwargs):
        """Ph∆∞∆°ng th·ª©c d·ª± ph√≤ng"""
        return self.embed_documents(texts, verbose=verbose)

# --- H√ÄM T·∫¢I T√ÄI NGUY√äN ---
@st.cache_resource
def load_resources():
    """T·∫£i m√¥ h√¨nh BERTopic v√† d·ªØ li·ªáu topic captions"""
    
    # T·∫£i DataFrame ch·ª©a th√¥ng tin c√°c ch·ªß ƒë·ªÅ
    if os.path.exists(TOPIC_INFO_PATH):
        df_topics = pd.read_csv(TOPIC_INFO_PATH)
    else:
        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {TOPIC_INFO_PATH}")
        df_topics = pd.DataFrame()

    # T·∫£i m√¥ h√¨nh BERTopic
    if os.path.exists(MODEL_PATH):
        try:
            model = BERTopic.load(MODEL_PATH)
            
            # S·ª≠ d·ª•ng wrapper class cho embedding model
            embedding_model = EmbeddingModelWrapper(EMBEDDING_MODEL_NAME)
            model.embedding_model = embedding_model
            
            st.success("‚úÖ M√¥ h√¨nh BERTopic ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
            
        except Exception as e:
            st.error(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {e}")
            model = None
    else:
        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh t·∫°i: {MODEL_PATH}")
        model = None
        
    return df_topics, model

# --- H√ÄM T√ìM T·∫ÆT V√ÉN B·∫¢N ---
def summarize_text(text, num_sentences=3):
    """
    T√≥m t·∫Øt vƒÉn b·∫£n b·∫±ng c√°ch l·∫•y N c√¢u ƒë·∫ßu ti√™n
    (C√≥ th·ªÉ thay th·∫ø b·∫±ng c√°c thu·∫≠t to√°n ph·ª©c t·∫°p h∆°n)
    """
    try:
        # T√°ch th√†nh c√°c c√¢u
        sentences = sent_tokenize(text)
        
        # L·∫•y s·ªë c√¢u c·∫ßn thi·∫øt
        if len(sentences) <= num_sentences:
            return text
        else:
            summary = ' '.join(sentences[:num_sentences])
            return summary + "..."
            
    except Exception as e:
        # Fallback: L·∫•y 300 k√Ω t·ª± ƒë·∫ßu
        return text[:300] + "..." if len(text) > 300 else text

# --- H√ÄM TI·ªÄN X·ª¨ L√ù VƒÇN B·∫¢N ---
def preprocess_text(text):
    """
    Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n ti·∫øng Vi·ªát:
    - L√†m s·∫°ch vƒÉn b·∫£n
    - T√°ch t·ª´ (tokenization)
    """
    # X√≥a kho·∫£ng tr·∫Øng th·ª´a
    text = re.sub(r'\s+', ' ', text).strip()
    
    # T√°ch t·ª´ ti·∫øng Vi·ªát
    tokenized = word_tokenize(text, format="text")
    
    return tokenized

# --- H√ÄM D·ª∞ ƒêO√ÅN TOPIC ---
def predict_topic(model, text, df_topics):
    """
    D·ª± ƒëo√°n topic ID v√† l·∫•y th√¥ng tin chi ti·∫øt
    """
    try:
        # T·∫°o embedding tr∆∞·ªõc
        embeddings = model.embedding_model.model.encode([text])
        
        # D·ª± ƒëo√°n topic v·ªõi embedding ƒë√£ t·∫°o s·∫µn
        topics, probs = model.transform([text], embeddings)
        topic_id = topics[0]
        confidence = probs[0][topic_id] if probs is not None else None
        
        # T√¨m th√¥ng tin topic trong DataFrame
        topic_row = df_topics[df_topics['Topic'] == topic_id]
        
        if not topic_row.empty:
            topic_name = topic_row.iloc[0]['Ten_Chu_De']
            keywords = topic_row.iloc[0]['Representation']
        else:
            topic_name = "Kh√¥ng x√°c ƒë·ªãnh"
            keywords = "Kh√¥ng c√≥ t·ª´ kh√≥a"
            
        return {
            'topic_id': topic_id,
            'topic_name': topic_name,
            'keywords': keywords,
            'confidence': confidence
        }
        
    except Exception as e:
        st.error(f"L·ªói khi d·ª± ƒëo√°n topic: {e}")
        return None

# --- C·∫§U H√åNH GIAO DI·ªÜN ---
st.set_page_config(
    page_title="BERTopic News Classifier", 
    page_icon="üì∞", 
    layout="wide"
)

# --- HEADER ---
st.title("üì∞ H·ªá th·ªëng Ph√¢n lo·∫°i & T√≥m t·∫Øt Tin t·ª©c")
st.markdown("""
**Ch·ª©c nƒÉng:**
- üîç Ph√¢n lo·∫°i vƒÉn b·∫£n v√†o c√°c ch·ªß ƒë·ªÅ tin t·ª©c
- üìù T√≥m t·∫Øt n·ªôi dung ch√≠nh
- üè∑Ô∏è Hi·ªÉn th·ªã t·ª´ kh√≥a ƒë·∫∑c tr∆∞ng

*Powered by BERTopic & Vietnamese SBERT*
""")

# T·∫£i t√†i nguy√™n
df_topics, bert_model = load_resources()

st.markdown("---")

# --- GIAO DI·ªÜN NH·∫¨P LI·ªÜU ---
col_input, col_settings = st.columns([3, 1])

with col_input:
    user_input = st.text_area(
        "üìÑ Nh·∫≠p vƒÉn b·∫£n tin t·ª©c (ti·∫øng Vi·ªát):",
        height=200,
        placeholder="V√≠ d·ª•: Ng√¢n h√†ng Nh√† n∆∞·ªõc v·ª´a c√¥ng b·ªë s·ªë li·ªáu v·ªÅ l√£i su·∫•t v√† t·ª∑ gi√° trong qu√Ω 3 nƒÉm 2024..."
    )

with col_settings:
    st.markdown("### ‚öôÔ∏è C√†i ƒë·∫∑t")
    num_summary_sentences = st.slider(
        "S·ªë c√¢u t√≥m t·∫Øt:", 
        min_value=1, 
        max_value=5, 
        value=3
    )
    
    show_tokenized = st.checkbox("Hi·ªÉn th·ªã vƒÉn b·∫£n sau t√°ch t·ª´", value=False)

# --- N√öT TH·ª∞C HI·ªÜN ---
if st.button("üöÄ Ph√¢n t√≠ch vƒÉn b·∫£n", type="primary", use_container_width=True):
    if not user_input.strip():
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p vƒÉn b·∫£n ƒë·ªÉ ph√¢n t√≠ch!")
    elif bert_model is None:
        st.error("‚ùå M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
    else:
        with st.spinner('üîÑ ƒêang x·ª≠ l√Ω vƒÉn b·∫£n...'):
            
            # B∆Ø·ªöC 1: T√≥m t·∫Øt vƒÉn b·∫£n
            summary_text = summarize_text(user_input, num_summary_sentences)
            
            # B∆Ø·ªöC 2: Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
            processed_text = preprocess_text(user_input)
            
            # B∆Ø·ªöC 3: D·ª± ƒëo√°n Topic
            result = predict_topic(bert_model, processed_text, df_topics)
            
            if result:
                # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
                st.success("‚úÖ Ph√¢n t√≠ch ho√†n t·∫•t!")
                st.markdown("---")
                
                # Layout 2 c·ªôt
                col1, col2 = st.columns([1, 1])
                
                with col1:
                    st.subheader("üéØ K·∫øt qu·∫£ Ph√¢n lo·∫°i")
                    
                    # Topic ID
                    st.metric(label="Topic ID", value=result['topic_id'])
                    
                    # T√™n ch·ªß ƒë·ªÅ
                    st.markdown(f"**üìå Ch·ªß ƒë·ªÅ:** `{result['topic_name']}`")
                    
                    # ƒê·ªô tin c·∫≠y (n·∫øu c√≥)
                    if result['confidence'] is not None:
                        confidence_percent = result['confidence'] * 100
                        st.progress(result['confidence'])
                        st.caption(f"ƒê·ªô tin c·∫≠y: {confidence_percent:.2f}%")
                    
                    # T·ª´ kh√≥a ƒë·∫∑c tr∆∞ng
                    st.markdown("**üîë T·ª´ kh√≥a ƒë·∫∑c tr∆∞ng:**")
                    st.code(result['keywords'], language="python")
                    
                    # VƒÉn b·∫£n sau t√°ch t·ª´ (t√πy ch·ªçn)
                    if show_tokenized:
                        with st.expander("üëÄ Xem vƒÉn b·∫£n sau t√°ch t·ª´"):
                            st.text(processed_text)
                
                with col2:
                    st.subheader("üìã T√≥m t·∫Øt N·ªôi dung")
                    st.info(summary_text)
                    
                    # Th·ªëng k√™ vƒÉn b·∫£n
                    st.markdown("**üìä Th·ªëng k√™:**")
                    stats_col1, stats_col2 = st.columns(2)
                    with stats_col1:
                        st.metric("ƒê·ªô d√†i g·ªëc", f"{len(user_input)} k√Ω t·ª±")
                    with stats_col2:
                        st.metric("ƒê·ªô d√†i t√≥m t·∫Øt", f"{len(summary_text)} k√Ω t·ª±")

# --- SIDEBAR ---
with st.sidebar:
    st.image("https://via.placeholder.com/300x100/4A90E2/FFFFFF?text=BERTopic", use_container_width=True)
    
    st.markdown("## üìñ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng")
    st.markdown("""
    1. D√°n vƒÉn b·∫£n tin t·ª©c v√†o √¥ nh·∫≠p li·ªáu
    2. Ch·ªçn s·ªë c√¢u mu·ªën t√≥m t·∫Øt
    3. Nh·∫•n n√∫t **Ph√¢n t√≠ch vƒÉn b·∫£n**
    4. Xem k·∫øt qu·∫£ ph√¢n lo·∫°i v√† t√≥m t·∫Øt
    """)
    
    st.markdown("---")
    st.markdown("## ‚ÑπÔ∏è Th√¥ng tin H·ªá th·ªëng")
    st.info(f"""
    **M√¥ h√¨nh:** BERTopic  
    **Embedding:** {EMBEDDING_MODEL_NAME}  
    **Ti·ªÅn x·ª≠ l√Ω:** Underthesea  
    **S·ªë ch·ªß ƒë·ªÅ:** {len(df_topics) if not df_topics.empty else 'N/A'}
    """)
    
    # Hi·ªÉn th·ªã danh s√°ch c√°c topic (t√πy ch·ªçn)
    if not df_topics.empty and st.checkbox("Xem danh s√°ch ch·ªß ƒë·ªÅ"):
        st.dataframe(
            df_topics[['Topic', 'Ten_Chu_De']].head(10),
            use_container_width=True,
            hide_index=True
        )

# --- FOOTER ---
st.markdown("---")
st.caption("¬© 2024 BERTopic News Classifier | Developed with Streamlit")